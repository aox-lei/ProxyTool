
爬虫代理IP池
=======

> 爬虫的时候经常需要代理ip过验证, 所以就提供了一套代理ip池的功能,其他功能后续就慢慢加入进去


### 1、问题

* 代理IP从何而来？

　　刚自学爬虫的时候没有代理IP就去西刺、快代理之类有免费代理的网站去爬，还是有个别代理能用。当然，如果你有更好的代理接口也可以自己接入。
　　
　　免费代理的采集也很简单，无非就是：访问页面页面 —> 正则/xpath提取 —> 保存

* 如何保证代理质量？

　　可以肯定免费的代理IP大部分都是不能用的，不然别人为什么还提供付费的(不过事实是很多代理商的付费IP也不稳定，也有很多是不能用)。所以采集回来的代理IP不能直接使用，可以写检测程序不断的去用这些代理访问一个稳定的网站，看是否可以正常使用。这个过程可以使用多线程或异步的方式，因为检测代理是个很慢的过程。

* 采集回来的代理如何存储？

　　代理ip保存在Mongo, 速度方面是一个保证, 而且结构足够自定义

* 如何让爬虫更简单的使用这些代理？

　 提供了web接口的服务, 在抓取之前, 请求api获取到代理ip直接使用即可

### 2、代理池设计

　　代理池由四部分组成:

* ProxyGetter:

　　代理获取接口，目前有5个免费代理源，每调用一次就会抓取这个5个网站的最新代理放入DB，可自行添加额外的代理获取接口；

### 3、安装

下载代码:
```
git clone https://github.com/mm333444/ProxyTool.git

或者直接到https://github.com/mm333444/ProxyTool下载zip文件
```

安装依赖:
```
pip install -r requirements.txt
```

启动:

```
如果你的依赖已经安全完成并且具备运行条件,可以直接在Run下运行main.py
到Run目录下:
>>>python run.py -env local
```

### 4、最后
　　时间仓促，功能和代码都比较简陋，以后有时间再改进。喜欢的在github上给个star。感谢！
